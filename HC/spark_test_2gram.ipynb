{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import zscore\n",
    "import gzip\n",
    "import os\n",
    "import csv\n",
    "from alive_progress import alive_bar\n",
    "from collections import defaultdict\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col, element_at, slice, size, regexp_extract, transform, when, explode, \\\n",
    "monotonically_increasing_id, map_from_arrays, lit, udf,collect_list, row_number, ceil, map_keys, expr, from_json\n",
    "from pyspark.sql.types import ShortType, ArrayType, LongType, StringType\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.conf import SparkConf\n",
    "import pandas as pd\n",
    "\n",
    "#path = 'C:/Users/bincl/BA-Thesis/Dataset/2gram/2_20000_nopos_ab.gz'\n",
    "start_date = 1800\n",
    "end_date = 2000\n",
    "directory_2gram = 'C:/Users/bincl/BA-Thesis/Dataset/2gram/parquet/'\n",
    "directory_1gram = 'C:/Users/bincl/BA-Thesis/Dataset/1gram/parquet/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.config(conf=conf).appName('NgramSQL').getOrCreate()\n",
    "spark = SparkSession.builder.appName('NgramSQL').getOrCreate()\n",
    "df_2gram = spark.read.option(\"header\",\"true\").option(\"recursiveFileLookup\",\"true\").parquet(directory_2gram)  \n",
    "\n",
    "df_1gram = spark.read.option(\"header\",\"true\").option(\"recursiveFileLookup\",\"true\").parquet(directory_1gram).cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if id set as default parameter then a list is given if not a spark dataframe is given as parameter df\n",
    "def get_pd_df(df):\n",
    "    matched = df['Data'] \n",
    "    matched_pandas_df = pd.Series(matched)\n",
    "    matched_pandas_df.sort_index(inplace = True)\n",
    "\n",
    "    matched_pandas_df.index.astype('int')\n",
    "    numbers = list(range(start_date,end_date))\n",
    "    numbers = map(str, numbers)\n",
    "    matched_pandas_df = matched_pandas_df.reindex(numbers, fill_value= 0)\n",
    "    return matched_pandas_df\n",
    "\n",
    "def get_pd_df_from_string(suchstring, df):\n",
    "    x = df.select(['Tokens', 'Data']).where(df.Tokens == suchstring)\n",
    "    matched = x.first()['Data']\n",
    "    matched_pandas_df = pd.Series(matched)\n",
    "    matched_pandas_df.sort_index(inplace = True)\n",
    "\n",
    "    matched_pandas_df.index.astype('int')\n",
    "    numbers = list(range(start_date,end_date))\n",
    "    numbers = map(str, numbers)\n",
    "    matched_pandas_df = matched_pandas_df.reindex(numbers, fill_value= 0)\n",
    "    return matched_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated zu langsam\n",
    "def find_n_gram(direc, find):\n",
    "    for filename in os.listdir(direc):\n",
    "        f = os.path.join(direc, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            with gzip.open(f,'rt', encoding='utf-8') as input:\n",
    "                str_arr_csv = input.readlines()\n",
    "                for line in str_arr_csv:\n",
    "                    token = line.split(\"\\t\")\n",
    "                    if find == token[0]:\n",
    "                        return line\n",
    "                        \n",
    "    return \"line not found\" \n",
    "\n",
    "def start_the_search(directory,search):\n",
    "    result = find_n_gram(directory,search)\n",
    "    \n",
    "    if result == \"line not found\":\n",
    "        print(result)\n",
    "        exit()\n",
    "    result = result.split(\"\\t\")\n",
    "    lower_ngram = pd.Series(result[1:],dtype= \"string\", name = result[0])\n",
    "    return lower_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLowerLevelString(string):\n",
    "   first, *middle, last = string.split()\n",
    "   if len(middle) != 0:\n",
    "        first = first + \" \" + ''.join(middle)\n",
    "        last = ''.join(middle) + \" \" + last    \n",
    "   return first, last\n",
    "\n",
    "def MLR(token,data):\n",
    "    y = data\n",
    "    first,last = getLowerLevelString(token)\n",
    "    first = get_pd_df_from_string(first,df_1gram)\n",
    "    last = get_pd_df_from_string(last,df_1gram)\n",
    "    X = pd.concat([first,last],axis=1)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y) \n",
    "    return reg.coef_,reg.intercept_,X,y\n",
    "\n",
    "def buildApproximation(c1,c2,basevalue,df):\n",
    "    df = df.astype('float')\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    df['scaledFirst'] = df.iloc[:,0].apply(lambda x: x * c1) \n",
    "    df['scaledLast'] = df.iloc[:,1].apply(lambda x: x * c2) \n",
    "    df['approximation'] = df['scaledFirst'] + df['scaledLast'] + basevalue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressWithError2gram(n,error):\n",
    "    df_2_gram = df_2gram.head(n)\n",
    "    result = []\n",
    "    all = []\n",
    "    sum = []\n",
    "    firstN = range(0,n)\n",
    "    \n",
    "    with alive_bar(len(firstN), force_tty = True, bar = 'smooth') as bar:\n",
    "        for i in firstN:\n",
    "            df_file = df_2_gram[i]\n",
    "            data = get_pd_df(df_file)\n",
    "            token = df_file['Tokens']\n",
    "            if not(data.eq(0).all()):\n",
    "                coef,intercept,dfAprox,original = MLR(token,data)\n",
    "                c1,c2 = coef\n",
    "                df = buildApproximation(c1,c2,intercept,dfAprox)\n",
    "                dfOriginal = pd.DataFrame()\n",
    "                dfOriginal['values'] = original\n",
    "                dfOriginal['values'] = dfOriginal['values'].apply(pd.to_numeric, errors='coerce')\n",
    "                #dfOriginal= pd.to_numeric(dfOriginal)\n",
    "                dfOriginal['zscore'] = zscore(dfOriginal)\n",
    "                df['zscore'] = zscore(df['approximation'])\n",
    "                sum.append(pd.to_numeric(dfOriginal['values']).sum()) \n",
    "                #sum.append(df_file['Sum']) \n",
    "                rmse = mean_squared_error(dfOriginal['zscore'], df['zscore'], squared = False)\n",
    "                #rmse = mean_squared_error(dfOriginal, df['approximation'])\n",
    "                if rmse <= error:\n",
    "                    result.append([token,rmse,dfOriginal['values'],dfOriginal['zscore'],df['approximation'],df['zscore']]) \n",
    "                all.append(rmse)    \n",
    "            bar()\n",
    "    return result, all, sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|▎⚠︎                                      | (!) 665/100000 [1%] in 1:04.0 (10.40/▅▇▇ 146/100000 [0%] in 17s (~3:09:29, ▆▄▂ 151/100000 [0%] in 17s (~3:08:22, ▅▇▇ 202/100000 [0%] in 22s (~2:59:54, ▃▁▃ 224/100000 [0%] in 24s (~2:57:21, ▄▂▂ 252/100000 [0%] in 26s (~2:54:32, ▁▃▅ 256/100000 [0%] in 27s (~2:53:58, ▅▇▇ 289/100000 [0%] in 30s (~2:50:58, ▇▇▅ 306/100000 [0%] in 31s (~2:49:37, ▃▅▇ 316/100000 [0%] in 32s (~2:49:04, ▅▃▁ 324/100000 [0%] in 33s (~2:48:42, ▄▂▂ 326/100000 [0%] in 33s (~2:48:35, ▅▇▇ 347/100000 [0%] in 35s (~2:47:20, ▅▇▇ 362/100000 [0%] in 36s (~2:46:24, ▂▄▆ 402/100000 [0%] in 40s (~2:44:56, █▆▄ 437/100000 [0%] in 43s (~2:43:41, ▅▇▇ 489/100000 [0%] in 48s (~2:42:46, ▄▆█ 515/100000 [1%] in 51s (~2:42:49, ▇▇▅ 547/100000 [1%] in 53s (~2:42:02, ▃▁▃ 554/100000 [1%] in 54s (~2:41:51, ▅▃▁ 566/100000 [1%] in 55s (~2:41:32, █▆▄ 637/100000 [1%] in 1:01 (~2:39:46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approximation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4138\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4138\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4140\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approximation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result, \u001b[38;5;28mall\u001b[39m, \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcompressWithError2gram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mall\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mcompressWithError2gram\u001b[1;34m(n, error)\u001b[0m\n\u001b[0;32m     14\u001b[0m coef,intercept,dfAprox,original \u001b[38;5;241m=\u001b[39m MLR(token,data)\n\u001b[0;32m     15\u001b[0m c1,c2 \u001b[38;5;241m=\u001b[39m coef\n\u001b[1;32m---> 16\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mbuildApproximation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mintercept\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdfAprox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m dfOriginal \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     18\u001b[0m dfOriginal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m original\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mbuildApproximation\u001b[1;34m(c1, c2, basevalue, df)\u001b[0m\n\u001b[0;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaledFirst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m c1) \n\u001b[0;32m     24\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaledLast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m c2) \n\u001b[1;32m---> 25\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapproximation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaledFirst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaledLast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m basevalue\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3977\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3977\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4184\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4181\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4182\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 4184\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4141\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4138\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4140\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 4141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1403\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_update_mgr_locs(loc)\n\u001b[1;32m-> 1403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_update_blklocs_and_blknos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_axis\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (block,)\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1443\u001b[0m, in \u001b[0;36mBlockManager._insert_update_blklocs_and_blknos\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blknos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bincl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:5617\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5615\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5616\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result, all, sum = compressWithError2gram(100000, 1)\n",
    "print(sum)\n",
    "print(all)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(all)\n",
    "plt.show()\n",
    "rmse_with_error = []\n",
    "\n",
    "for i in result:\n",
    "    rmse_with_error.append(i[1])\n",
    "plt.boxplot(rmse_with_error)\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(x= rmse_with_error, inner=\"point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "result[n][2].plot()\n",
    "result[n][4].plot()\n",
    "plt.show()\n",
    "result[n][3].plot()\n",
    "result[n][5].plot()\n",
    "plt.show()\n",
    "print(result[n][0])\n",
    "print(result[n][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x= all, inner_kws=dict(box_width=15, whis_width=2, color=\".8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(sum, all)\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "print(\"2gram test 30 min für 10000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

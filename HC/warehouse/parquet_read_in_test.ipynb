{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import zscore\n",
    "import gzip\n",
    "import os\n",
    "import csv\n",
    "from alive_progress import alive_bar\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col, element_at, slice, size, regexp_extract, transform, when, explode, \\\n",
    "monotonically_increasing_id, map_from_arrays, lit, udf,collect_list, row_number, ceil, map_keys, expr, from_json\n",
    "from pyspark.sql.types import ShortType, ArrayType, LongType, StringType\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.conf import SparkConf\n",
    "import pandas as pd\n",
    "\n",
    "#path = 'C:/Users/bincl/BA-Thesis/Dataset/2gram/2_20000_nopos_ab.gz'\n",
    "start_date = 1800\n",
    "end_date = 2000\n",
    "directory_3gram = 'C:/Users/bincl/BA-Thesis/Dataset/3gram/parquet/3_20000_nopos_sample/3_20000_nopos_sample.gz/'\n",
    "directory_2gram = 'C:/Users/bincl/BA-Thesis/Dataset/2gram/parquet/orderBy/2gram_order/'\n",
    "\n",
    "conf= SparkConf().setAll([('spark.executor.memory', '16g'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','16g'),('spark.sql.sources.pushdown.pushdownEnabled', 'true')])\n",
    "spark = SparkSession.builder.config(conf=conf).appName('NgramSQL').getOrCreate()\n",
    "\n",
    "#spark = SparkSession.builder.appName('3gramSQL').getOrCreate()\n",
    "df_3gram = spark.read.parquet(directory_3gram)   \n",
    "df_2gram = spark.read.parquet(directory_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_df(df):\n",
    "    matched = df['Data'] \n",
    "    matched_pandas_df = pd.Series(matched)\n",
    "    matched_pandas_df.sort_index(inplace = True)\n",
    "\n",
    "    matched_pandas_df.index.astype('int')\n",
    "    numbers = list(range(start_date,end_date))\n",
    "    numbers = map(str, numbers)\n",
    "    matched_pandas_df = matched_pandas_df.reindex(numbers, fill_value= 0)\n",
    "    return matched_pandas_df\n",
    "\n",
    "def get_pd_df_from_string(suchstring, df):\n",
    "    x = df.select(['Tokens', 'Data']).where(df.Tokens == suchstring).limit(1)\n",
    "    matched = x.first()['Data']\n",
    "    matched_pandas_df = pd.Series(matched)\n",
    "    matched_pandas_df.sort_index(inplace = True)\n",
    "\n",
    "    matched_pandas_df.index.astype('int')\n",
    "    numbers = list(range(start_date,end_date))\n",
    "    numbers = map(str, numbers)\n",
    "    matched_pandas_df = matched_pandas_df.reindex(numbers, fill_value= 0)\n",
    "    return matched_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLowerLevelString(string):\n",
    "   first, *middle, last = string.split()\n",
    "   if len(middle) != 0:\n",
    "        first = first + \" \" + ''.join(middle)\n",
    "        last = ''.join(middle) + \" \" + last    \n",
    "   return first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Tokens='Erkenntnisse und Methoden', Data={'1855': 1, '1976': 217, '1975': 167, '1974': 211, '1973': 239, '1851': 3, '1972': 174, '1971': 212, '1970': 205, '1979': 237, '1978': 212, '1977': 219, '1909': 11, '1908': 1, '1990': 245, '1987': 202, '1986': 203, '1985': 235, '1984': 237, '1983': 316, '1982': 263, '1981': 279, '1980': 312, '1906': 18, '1905': 3, '1903': 3, '1902': 3, '1901': 4, '1989': 201, '1900': 1, '1988': 215, '1910': 12, '1998': 205, '1876': 3, '1997': 169, '1996': 153, '1874': 2, '1995': 148, '1994': 205, '1993': 183, '1992': 192, '1991': 205, '1918': 3, '1917': 11, '1916': 4, '1914': 9, '1913': 22, '1912': 1, '1911': 4, '1999': 177, '1888': 8, '1921': 8, '1920': 8, '1929': 18, '1928': 10, '1927': 28, '1926': 5, '1925': 4, '1924': 5, '1923': 2, '1922': 4, '1932': 9, '1898': 2, '1931': 7, '1897': 4, '1930': 18, '1896': 1, '1939': 12, '1938': 15, '1937': 17, '1936': 12, '1935': 17, '1934': 24, '1933': 24, '2001': 153, '2000': 169, '1943': 14, '1942': 12, '1941': 12, '1940': 4, '1949': 20, '1948': 20, '1947': 8, '1946': 12, '1945': 1, '1944': 2, '2012': 197, '2011': 213, '2010': 260, '1954': 42, '2009': 274, '1953': 32, '2008': 263, '1952': 33, '2007': 314, '1951': 43, '2006': 239, '1950': 29, '2005': 242, '2004': 239, '2003': 218, '2002': 206, '1959': 79, '1958': 62, '1957': 37, '1956': 84, '1955': 44, '1965': 112, '1964': 120, '2019': 157, '1963': 98, '2018': 258, '1962': 73, '2017': 223, '1961': 84, '2016': 284, '1960': 52, '2015': 278, '2014': 224, '2013': 664, '1969': 210, '1968': 236, '1967': 185, '1966': 142}, Sum=13796)\n"
     ]
    }
   ],
   "source": [
    "df = df_3gram.head(10)\n",
    "print(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in df:\n",
    "    first, last = getLowerLevelString(d[\"Tokens\"])\n",
    "    \n",
    "    x = df_2gram.select(['Tokens', 'Data']).where(df_2gram.Tokens == first).limit(1)\n",
    "    d_first = x.first()['Data']\n",
    "\n",
    "    x = df_2gram.select(['Tokens', 'Data']).where(df_2gram.Tokens == last).limit(1)\n",
    "    d_last = x.first()['Data'] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_3gram.head(1000)\n",
    "for d in df:\n",
    "    first, last = getLowerLevelString(d[\"Tokens\"])\n",
    "    \n",
    "    x = df_2gram.select(['Tokens','Sum']).where(df_2gram.Tokens == first).limit(1)\n",
    "    d_first = x.first()['Tokens']\n",
    "\n",
    "    x = df_2gram.select(['Tokens','Sum']).where(df_2gram.Tokens == last).limit(1)\n",
    "    d_last = x.first()['Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_3gram.head(10)\n",
    "for d in df:\n",
    "    first, last = getLowerLevelString(d[\"Tokens\"])\n",
    "    \n",
    "    x = df_2gram.select(['Data']).where(df_2gram.Tokens == first).limit(1)\n",
    "    d_first = x.first()['Data']\n",
    "\n",
    "    x = df_2gram.select(['Data']).where(df_2gram.Tokens == last).limit(1)\n",
    "    d_last = x.first()['Data'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3gram = df_3gram.withColumn('last_two_words', expr(\"substring_index(Tokens, ' ', -2)\"))\n",
    "df_3gram = df_3gram.withColumn('first_two_words', expr(\"substring_index(Tokens, ' ', 2)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3gram = df_3gram.join(df_2gram.alias(\"last\"), df_3gram['last_two_words'] == col(\"last.Tokens\"))\n",
    "joined_df = df_3gram.join(df_2gram.alias(\"first\"), df_3gram['first_two_words'] == col(\"first.Tokens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tokens: string (nullable = true)\n",
      " |-- Data: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- Sum: integer (nullable = true)\n",
      " |-- last_two_words: string (nullable = true)\n",
      " |-- first_two_words: string (nullable = true)\n",
      " |-- Tokens: string (nullable = true)\n",
      " |-- Data: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- Sum: integer (nullable = true)\n",
      " |-- Tokens: string (nullable = true)\n",
      " |-- Data: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- Sum: integer (nullable = true)\n",
      " |-- Tokens: string (nullable = true)\n",
      " |-- Data: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- Sum: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joined_df.head(10)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
